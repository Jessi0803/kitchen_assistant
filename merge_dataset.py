#!/usr/bin/env python3
"""
æ•°æ®é›†èšåˆè„šæœ¬ - å°†æ‰€æœ‰foodç±»åˆ«çš„imageså’Œlabelsåˆå¹¶åˆ°ç»Ÿä¸€æ–‡ä»¶å¤¹
Merge all food category datasets into unified images and labels folders
"""

import os
import shutil
from pathlib import Path
from collections import defaultdict
import yaml

def scan_dataset_structure(datasets_dir):
    """æ‰«ædatasetsæ–‡ä»¶å¤¹ï¼Œè¯†åˆ«æ‰€æœ‰åŒ…å«imageså’Œlabelsçš„å­æ–‡ä»¶å¤¹"""
    datasets_dir = Path(datasets_dir)
    found_paths = []
    
    print("ğŸ” æ‰«ææ•°æ®é›†ç»“æ„...")
    
    # éå†æ‰€æœ‰foodç±»åˆ«æ–‡ä»¶å¤¹
    for food_category in datasets_dir.iterdir():
        if food_category.is_dir() and food_category.name not in ['.DS_Store', '__pycache__']:
            print(f"\nğŸ“ æ£€æŸ¥ç±»åˆ«: {food_category.name}")
            
            # æŸ¥æ‰¾train/test/validç­‰æ–‡ä»¶å¤¹
            for split_folder in food_category.iterdir():
                if split_folder.is_dir() and split_folder.name in ['train', 'test', 'valid', 'val']:
                    images_path = split_folder / 'images'
                    labels_path = split_folder / 'labels'
                    
                    if images_path.exists() and labels_path.exists():
                        image_count = len(list(images_path.glob('*.jpg'))) + len(list(images_path.glob('*.png')))
                        label_count = len(list(labels_path.glob('*.txt')))
                        
                        found_paths.append({
                            'category': food_category.name,
                            'split': split_folder.name,
                            'images_path': images_path,
                            'labels_path': labels_path,
                            'image_count': image_count,
                            'label_count': label_count
                        })
                        
                        print(f"  âœ… {split_folder.name}: {image_count} images, {label_count} labels")
                    else:
                        print(f"  âš ï¸  {split_folder.name}: ç¼ºå°‘imagesæˆ–labelsæ–‡ä»¶å¤¹")
    
    return found_paths

def merge_datasets(datasets_dir, output_dir, test_ratio=0.15, val_ratio=0.15):
    """åˆå¹¶æ‰€æœ‰æ•°æ®é›†åˆ°ç»Ÿä¸€æ–‡ä»¶å¤¹ - æ‰€æœ‰imageså’Œlabelsèšåˆåˆ°å•ä¸€æ–‡ä»¶å¤¹"""
    datasets_dir = Path(datasets_dir)
    output_dir = Path(output_dir)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„ - ç»Ÿä¸€çš„imageså’Œlabelsæ–‡ä»¶å¤¹
    merged_images = output_dir / 'images'
    merged_labels = output_dir / 'labels'
    
    # åˆ›å»ºç›®å½•
    merged_images.mkdir(parents=True, exist_ok=True)
    merged_labels.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ“ åˆ›å»ºåˆå¹¶ç›®å½•: {output_dir}")
    
    # æ‰«ææ‰€æœ‰æ•°æ®é›†
    found_paths = scan_dataset_structure(datasets_dir)
    
    total_images = 0
    total_labels = 0
    category_stats = defaultdict(int)
    file_conflicts = []
    
    print(f"\nğŸ”„ å¼€å§‹åˆå¹¶æ•°æ®é›†...")
    
    for data_info in found_paths:
        category = data_info['category']
        split = data_info['split']
        images_path = data_info['images_path']
        labels_path = data_info['labels_path']
        
        print(f"\nå¤„ç†: {category}/{split}")
        
        # æ‰€æœ‰æ•°æ®éƒ½æ”¾åˆ°ç»Ÿä¸€çš„imageså’Œlabelsæ–‡ä»¶å¤¹ä¸­
        target_images_dir = merged_images
        target_labels_dir = merged_labels
        
        # å¤åˆ¶å›¾ç‰‡æ–‡ä»¶
        for img_file in images_path.glob('*.*'):
            if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åé¿å…å†²çª
                new_name = f"{category}_{split}_{img_file.name}"
                target_path = target_images_dir / new_name
                
                if target_path.exists():
                    file_conflicts.append(f"å›¾ç‰‡å†²çª: {new_name}")
                    new_name = f"{category}_{split}_{total_images}_{img_file.name}"
                    target_path = target_images_dir / new_name
                
                shutil.copy2(img_file, target_path)
                total_images += 1
                category_stats[category] += 1
        
        # å¤åˆ¶æ ‡ç­¾æ–‡ä»¶
        for label_file in labels_path.glob('*.txt'):
            # ç¡®ä¿æ ‡ç­¾æ–‡ä»¶åä¸å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶ååŒ¹é…
            img_base_name = label_file.stem
            
            # æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
            corresponding_img = None
            for ext in ['.jpg', '.jpeg', '.png']:
                img_path = images_path / f"{img_base_name}{ext}"
                if img_path.exists():
                    corresponding_img = img_path
                    break
            
            if corresponding_img:
                # ä½¿ç”¨ä¸å›¾ç‰‡ç›¸åŒçš„å‘½åè§„åˆ™
                new_img_name = f"{category}_{split}_{corresponding_img.name}"
                new_label_name = f"{category}_{split}_{label_file.name}"
                
                # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨å†²çªï¼Œå¦‚æœæœ‰åˆ™ä½¿ç”¨ç›¸åŒçš„è§£å†³æ–¹æ¡ˆ
                target_img_path = target_images_dir / new_img_name
                if not target_img_path.exists():
                    # å¯»æ‰¾å®é™…çš„å›¾ç‰‡æ–‡ä»¶å
                    for existing_img in target_images_dir.glob(f"{category}_{split}_*"):
                        if existing_img.stem.endswith(img_base_name):
                            new_label_name = existing_img.stem + '.txt'
                            break
                
                target_label_path = target_labels_dir / new_label_name
                
                if target_label_path.exists():
                    file_conflicts.append(f"æ ‡ç­¾å†²çª: {new_label_name}")
                    new_label_name = f"{category}_{split}_{total_labels}_{label_file.name}"
                    target_label_path = target_labels_dir / new_label_name
                
                shutil.copy2(label_file, target_label_path)
                total_labels += 1
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š åˆå¹¶å®Œæˆç»Ÿè®¡:")
    print(f"æ€»å›¾ç‰‡æ•°: {total_images}")
    print(f"æ€»æ ‡ç­¾æ•°: {total_labels}")
    print(f"\nå„ç±»åˆ«å›¾ç‰‡æ•°é‡:")
    for category, count in category_stats.items():
        print(f"  {category}: {count}")
    
    if file_conflicts:
        print(f"\nâš ï¸  æ–‡ä»¶åå†²çªè§£å†³æ•°é‡: {len(file_conflicts)}")
        for conflict in file_conflicts[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  {conflict}")
        if len(file_conflicts) > 5:
            print(f"  ... è¿˜æœ‰ {len(file_conflicts) - 5} ä¸ªå†²çª")
    
    # è®¡ç®—åˆå¹¶åçš„æ€»æ•°é‡
    merged_images_count = len(list(merged_images.glob('*.*')))
    merged_labels_count = len(list(merged_labels.glob('*.*')))
    
    print(f"\nğŸ“ˆ åˆå¹¶åæ•°æ®é›†:")
    print(f"  æ€»å›¾ç‰‡æ•°: {merged_images_count}")
    print(f"  æ€»æ ‡ç­¾æ•°: {merged_labels_count}")
    
    return {
        'total_images': total_images,
        'total_labels': total_labels,
        'category_stats': dict(category_stats),
        'merged_images_count': merged_images_count,
        'merged_labels_count': merged_labels_count,
        'conflicts': len(file_conflicts)
    }

def get_class_names(datasets_dir):
    """ä»data.yamlæ–‡ä»¶ä¸­æå–æ‰€æœ‰ç±»åˆ«åç§°"""
    datasets_dir = Path(datasets_dir)
    all_classes = set()
    
    print("\nğŸ·ï¸  æå–ç±»åˆ«æ ‡ç­¾...")
    
    for food_category in datasets_dir.iterdir():
        if food_category.is_dir():
            data_yaml = food_category / 'data.yaml'
            if data_yaml.exists():
                try:
                    with open(data_yaml, 'r') as f:
                        data = yaml.safe_load(f)
                    
                    if 'names' in data:
                        if isinstance(data['names'], dict):
                            # namesæ˜¯å­—å…¸æ ¼å¼ {0: 'class1', 1: 'class2'}
                            classes = list(data['names'].values())
                        else:
                            # namesæ˜¯åˆ—è¡¨æ ¼å¼ ['class1', 'class2']
                            classes = data['names']
                        
                        print(f"  {food_category.name}: {classes}")
                        all_classes.update(classes)
                        
                except Exception as e:
                    print(f"  âš ï¸  è¯»å– {food_category.name}/data.yaml å¤±è´¥: {e}")
    
    return sorted(list(all_classes))

def create_merged_config(output_dir, class_names):
    """ä¸ºåˆå¹¶åçš„æ•°æ®é›†åˆ›å»ºYOLOæ ¼å¼çš„é…ç½®æ–‡ä»¶"""
    output_dir = Path(output_dir)
    
    # åˆ›å»ºç±»åˆ«åç§°æ˜ å°„
    names_dict = {i: name for i, name in enumerate(class_names)}
    
    config = {
        'path': str(output_dir.absolute()),
        'train': 'images',  # æ‰€æœ‰æ•°æ®éƒ½åœ¨ç»Ÿä¸€çš„imagesæ–‡ä»¶å¤¹ä¸­
        'val': 'images',    # æŒ‡å‘åŒä¸€ä¸ªimagesæ–‡ä»¶å¤¹
        'test': 'images',   # æŒ‡å‘åŒä¸€ä¸ªimagesæ–‡ä»¶å¤¹
        'nc': len(class_names),
        'names': names_dict
    }
    
    # ä¿å­˜é…ç½®æ–‡ä»¶
    config_path = output_dir / 'data.yaml'
    with open(config_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False)
    
    print(f"\nğŸ“„ é…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_path}")
    print(f"ç±»åˆ«æ•°é‡: {len(class_names)}")
    print(f"ç±»åˆ«åç§°: {class_names}")
    
    return config_path

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ³ Kitchen Assistant - æ•°æ®é›†èšåˆå·¥å…·")
    print("=" * 60)
    
    # è®¾ç½®è·¯å¾„
    datasets_dir = Path(__file__).parent / 'datasets'
    output_dir = Path(__file__).parent / 'datasets' / 'merged_food_dataset'
    
    if not datasets_dir.exists():
        print(f"âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {datasets_dir}")
        return
    
    # ç¡®è®¤æ“ä½œ
    print(f"ğŸ“‚ æºç›®å½•: {datasets_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    if output_dir.exists():
        response = input(f"\nâš ï¸  è¾“å‡ºç›®å½•å·²å­˜åœ¨ï¼Œæ˜¯å¦è¦†ç›–? (y/N): ")
        if response.lower() not in ['y', 'yes']:
            print("âŒ æ“ä½œå·²å–æ¶ˆ")
            return
        shutil.rmtree(output_dir)
    
    try:
        # 1. åˆå¹¶æ•°æ®é›†
        stats = merge_datasets(datasets_dir, output_dir)
        
        # 2. è·å–ç±»åˆ«åç§°
        class_names = get_class_names(datasets_dir)
        
        # 3. åˆ›å»ºé…ç½®æ–‡ä»¶
        config_path = create_merged_config(output_dir, class_names)
        
        print(f"\nâœ… æ•°æ®é›†èšåˆå®Œæˆ!")
        print(f"ğŸ“Š æ€»ç»Ÿè®¡:")
        print(f"  - å›¾ç‰‡æ€»æ•°: {stats['total_images']}")
        print(f"  - æ ‡ç­¾æ€»æ•°: {stats['total_labels']}")
        print(f"  - ç±»åˆ«æ€»æ•°: {len(class_names)}")
        print(f"  - åˆå¹¶åå›¾ç‰‡: {stats['merged_images_count']}")
        print(f"  - åˆå¹¶åæ ‡ç­¾: {stats['merged_labels_count']}")
        
        print(f"\nğŸ¯ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹é…ç½®å¼€å§‹è®­ç»ƒ:")
        print(f"  é…ç½®æ–‡ä»¶: {config_path}")
        print(f"  æ•°æ®é›†è·¯å¾„: {output_dir}")
        
        print(f"\nğŸ’¡ è®­ç»ƒå‘½ä»¤ç¤ºä¾‹:")
        print(f"  python fine_tune_yolo.py --dataset {config_path}")
        
    except Exception as e:
        print(f"âŒ åˆå¹¶è¿‡ç¨‹å‡ºé”™: {e}")
        raise

if __name__ == "__main__":
    main()
